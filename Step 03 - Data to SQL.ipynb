{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 03 - Data to SQL\n",
    "Projects with big data files better to store data in a database instead of separate excel files.\n",
    "We have incoming data in excel files. We need to add the data from excel files to our database. For this we create an .sql file in which we have a an \"INSERT\" query in each row. The name of our database is meter_reading, each record has a `site name`, a `datetime`, a `value` and 3 more attributes which have no role here. (We need to leave an empty string at these places)\n",
    "\n",
    "The rows in the output .sql file should look like:\n",
    "\n",
    "INSERT INTO meter_reading (`site name`, '', `datetime`, `value`, '', '');  \n",
    "INSERT INTO meter_reading (`site name`, '', `datetime`, `value`, '', '');  \n",
    "INSERT INTO meter_reading (`site name`, '', `datetime`, `value`, '', '');  \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noutput format: .sql\\noutput like:\\n    insert into meter_reading ('<site name>', '<leave it empty>', '<datetime>', '<value>');\\n    insert into meter_reading ('<site name>', '<leave it empty>', '<datetime>', '<value>');\\n    insert into meter_reading ('<site name>', '<leave it empty>', '<datetime>', '<value>');\\n    ...\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xls = pd.ExcelFile(\"Stark Anonymised Data Pack 1.xlsx\")\n",
    "sheet_to_df_map = {}\n",
    "for sheetName in xls.sheet_names:\n",
    "    if 'Site' in sheetName:\n",
    "        sheet_to_df_map[sheetName] = xls.parse(sheetName)\n",
    "'''now we have a dict containing site name -\n",
    "- the data of that site in dataframe data pairs'''\n",
    "    \n",
    "'''\n",
    "output format: .sql\n",
    "output like:\n",
    "    insert into meter_reading ('<site name>', '<leave it empty>', '<datetime>', '<value>', '<leave it empty>', '<leave it empty>');\n",
    "    insert into meter_reading ('<site name>', '<leave it empty>', '<datetime>', '<value>', '<leave it empty>', '<leave it empty>');\n",
    "    insert into meter_reading ('<site name>', '<leave it empty>', '<datetime>', '<value>', '<leave it empty>', '<leave it empty>');\n",
    "    ...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data.sql', 'a+')\n",
    "\n",
    "for sheet in sheet_to_df_map.keys():\n",
    "    d = sheet_to_df_map[sheet]\n",
    "    checkTimeDifference(d)\n",
    "    times =  getTimes(d)\n",
    "    for j in range(d.shape[0]):\n",
    "        for i in range(1,len(times)+1):\n",
    "            value = d.iat[j,i]\n",
    "\n",
    "            col = times[i-1]\n",
    "            seconds = (col.hour * 60 + col.minute) * 60 + col.second\n",
    "            Datetime = d['Date'][j] + datetime.timedelta(0,seconds)\n",
    "            nextLine = 'insert into meter_reading values (\\''+str(sheet)+'\\', \\'\\', \\''+str(Datetime)+'\\', \\''+str(value)+'\\', \\'\\', \\'\\');'\n",
    "            f.write(nextLine+'\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTimes(d):\n",
    "    '''\n",
    "    Returns a list of the time columns of\n",
    "    the sheet.\n",
    "    '''\n",
    "    times = d.columns.tolist()\n",
    "    for i in times:\n",
    "        if type(i) != datetime.time:\n",
    "            times.remove(i)\n",
    "    # somehow it skips the last column ->\n",
    "    # have to manage it separately\n",
    "    if type(times[-1]) != datetime.time:\n",
    "        times.remove(times[-1])\n",
    "    return times\n",
    "\n",
    "def checkTimeDifference(d):\n",
    "    '''\n",
    "    For every site we call this function. \n",
    "    First it checks if the time step between\n",
    "    columns is correct (30 mins).\n",
    "    It also returns the number of columns with data\n",
    "    (note: the first column is date, and the last \n",
    "    few is rubbish.) -> later we can iterate this long.\n",
    "    '''\n",
    "    last = 0\n",
    "    numberOfDataColumns = 0\n",
    "    check = datetime.datetime(100,1,1,0,30,0) # use this to check if we have data for every 30 mins\n",
    "    for col in d.columns:\n",
    "        if type(col) == datetime.time:\n",
    "            numberOfDataColumns += 1\n",
    "        if type(last) == datetime.time and type(col) == datetime.time:\n",
    "            # timedelta only works with date-s but our columns are time-s\n",
    "            # need to create a date variable to check (might  be a bit confusing)\n",
    "            seconds = (col.hour * 60 + col.minute) * 60 + col.second\n",
    "            current = datetime.datetime(100,1,1,0,0,0) + datetime.timedelta(0,seconds-30*60)\n",
    "            if last != current.time():\n",
    "                print(f'ERROR! Difference between columns \"{col}\" and \"{last}\" is NOT 30 mins.')\n",
    "                break\n",
    "        last = col\n",
    "    return numberOfDataColumns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
